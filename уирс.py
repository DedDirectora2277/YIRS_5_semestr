# -*- coding: utf-8 -*-
"""УИРС.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mZMIATAjBBCER1sKXLvanuGpslv0gg_k
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn import metrics
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
from sklearn.linear_model import Lasso
from sklearn.ensemble import RandomForestRegressor

df = pd.read_csv('Training_set.csv', ';')

df

"""Функция для определения числа пропущенных значений по столбцам"""

def missings(df):
  df_miss = pd.DataFrame()
  df_miss['Not miss'] = df.notna().sum()
  df_miss['Miss'] = df.isna().sum()
  return df_miss
missings(df)

"""Проверка на дубликаты"""

def print_dups(df):
  count = df.duplicated().sum()
  print(f'Duplicates: {count}')

print_dups(df)

df.drop_duplicates(inplace = True)
print_dups(df)
df.reset_index(drop = True, inplace = True) #Обновление индексов

"""Проверка на выбросы"""

def print_outl(df, feature):
  lowest = df.sort_values([feature])[feature][:5]
  highest = df.sort_values([feature])[feature][-5:]
  print(f'The lowest values of {feature} feature: ')
  print(lowest)
  print(f'The highest values of {feature} feature: ')
  print(highest)
  print()

for column_name in df.columns:
  print_outl(df, column_name)

"""Проверка на мультиколлинеарность (линейная)"""

corr_table = df.corr().style.background_gradient(cmap = 'viridis')
corr_table

"""Можно заметить, что температура окружающего воздуха значительно коррелирует с выходной тягой. Имеет смысл проверить как повлияет удаление одного из собцов на результат обучения"""

def del_feature(df, feature):
  return df.drop(feature, axis=1)

"""Все данные из дата сета являются числовыми

"""

df.describe()

"""**Описание данных**

Гистограммы
"""

def plot_hists(df):
  numeric_features = df.columns

  num_plots = len(numeric_features)
  num_cols = 2
  num_rows = (num_plots // num_cols) + (num_plots % num_cols)

  fig, axes = plt.subplots(num_rows, num_cols, figsize=(10, 5*num_rows))

  # Разворачиваем двумерный массив осей в одномерный для удобства индексации
  axes = axes.ravel()

  for i, column in enumerate(numeric_features):
    sns.histplot(df[column], bins=30, ax=axes[i])
    axes[i].set_title(f'Distribution of {column}')

  plt.tight_layout()
  plt.show()
plot_hists(df)

"""Ящики с усами"""

def plot_box(df):

    numeric_columns = df.columns

    # Строим ящики с усами для каждого числового атрибута
    for column in numeric_columns:
        plt.figure(figsize=(8, 6))
        plt.boxplot(df[column], vert=False)
        plt.title(f'Box Plot for {column}')
        plt.xlabel('Values')
        plt.show()
plot_box(df)

"""Диаграммы зависимостей"""

def plot_pairs(df):
  sns.pairplot(df)
  plt.show()
plot_pairs(df)

"""Создание тестового дата сета

"""

def get_train_test_dfs(df, target_col):
  X = df.drop(columns=[target_col])
  Y = df[target_col]
  X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)
  return X_train, X_test, Y_train, Y_test
X_train, X_test, Y_train, Y_test = get_train_test_dfs(df, 'PE')
print(f'X_train shape: {X_train.shape}')
print(f'X_test shape: {X_test.shape}')
print(f'Y_train shape: {Y_train.shape}')
print(f'Y_test shape: {Y_test.shape}')

"""Обучение модели линейной регрессии"""

def linear_regression(X_train, y_train, X_test, Y_test):
    # Инициализация модели
    model = LinearRegression()

    # Обучение модели
    model.fit(X_train, y_train)
    Y_pred = model.predict(X_test)
    print(f'MAE linear regression: {mean_absolute_error(Y_test, Y_pred)}') #Средняя абсолютная ошибка
    print(f'MSE linear regression: {mean_squared_error(Y_test, Y_pred)}') #Средняя квадратичная ошибка
    print(f'R2 Score linear regression: {r2_score(Y_test, Y_pred)}') #R2 метрика

"""Оценка обучения"""

linear_regression(X_train, Y_train, X_test, Y_test)

"""Можно заметить, что линейная регрессия отлично подходит для данной задачи

Удалим один из коррелирующих столбцов и повторим обучение модели
"""

df_2 = del_feature(df, 'EV')
X_train2, X_test2, Y_train2, Y_test2 = get_train_test_dfs(df_2, 'PE')

linear_regression(X_train2, Y_train2, X_test2, Y_test2)

"""Удаление одного из коррелирующих атрибутов привело к незначительному снижению точности предсказания

Применение Lasso регрессии
"""

def lasso_regression(X_train, Y_train, X_test, Y_test):
  model_LASSO = Lasso(alpha = 1)
  model_LASSO.fit(X_train, Y_train)
  coeffs = pd.Series(model_LASSO.coef_, index=X_train.columns)
  insignificant_features = list(coeffs[abs(coeffs) < 0.1].index)
  print('Insignificant features: ', insignificant_features)
  Y_predL = model_LASSO.predict(X_test)
  print(f'MAE lasso: {mean_absolute_error(Y_test, Y_predL)}') #Средняя абсолютная ошибка
  print(f'MSE lasso: {mean_squared_error(Y_test, Y_predL)}') #Средняя квадратичная ошибка
  print(f'R2 Score lasso: {r2_score(Y_test, Y_predL)}') #R2 метрика

lasso_regression(X_train, Y_train, X_test, Y_test)

"""Можно заметить, что после LASSO регрессии точность практически осталась той же, но также был выявлен атрибут незначительно влияющий на результат обучения ('AP')

Удалим атрибут 'AP'
"""

df_3 = del_feature(df, 'AP')
X_train3, X_test3, Y_train3, Y_test3 = get_train_test_dfs(df_3, 'PE')

lasso_regression(X_train3, Y_train3, X_test3, Y_test3)

linear_regression(X_train3, Y_train3, X_test3, Y_test3)

"""**Используем модель регрессии случайного леса**"""

def random_forest_regression(X_train, Y_train, X_test, Y_test):
  model_RF = RandomForestRegressor(n_estimators=100)
  model_RF.fit(X_train, Y_train)
  Y_predRF = model_RF.predict(X_test)
  print(f'MAE: {mean_absolute_error(Y_test, Y_predRF)}') #Средняя абсолютная ошибка
  print(f'MSE: {mean_squared_error(Y_test, Y_predRF)}') #Средняя квадратичная ошибка
  print(f'R2 Score: {r2_score(Y_test, Y_predRF)}') #R2 метрика

"""С атрибутом AP"""

random_forest_regression(X_train, Y_train, X_test, Y_test)

"""Без атрибута AP"""

random_forest_regression(X_train3, Y_train3, X_test3, Y_test3)